<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.14"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>ASPiK SDK: Buffer vs. Frame Processing</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
  $(document).ready(initResizable);
/* @license-end */</script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">ASPiK SDK
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.14 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(document).ready(function(){initNavTree('define_plugin7.html','');});
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="headertitle">
<div class="title">Buffer vs. Frame Processing </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p>We have finally arrived at the function that will do all of the cool audio processing stuff our plugin was designed for. At this point, you need to make a fairly critical decision about how that processing will occur – by buffer or by frame. All APIs deliver audio data to the buffer processing function in separated buffers, one for each channel. If we assemble one audio sample from each channel for each sample period, we create a frame. So a set of channel buffers containing M samples each would be broken into M frames. A stereo input frame would consist of an array that contains two audio samples, one for the left channel and one for the right. We might indicate that as {left, right}. A frame of surround sound 5.1 audio data is an array of six audio samples, one from each channel, organized in the following manner: {left, right, center, LFE, left surround, right surround} where LFE stands for “Low Frequency Effects” or the sub-woofer channel. <br />
 <br />
 In the <a class="el" href="class_plugin_core.html" title="The PluginCore object is the default PluginBase derived object for ASPiK projects. Note that you are fre to change the name of this object (as long as you change it in the compiler settings, etc...) ">PluginCore</a>, you may choose whether you want to process complete buffers or frames of data. There may be good reasons for choosing one or the other. For example, if your plugin implemented a simple filter operation, you might process the channel buffers since the audio data in them is unrelated as far as your plugin is concerned. But if your plugin required information from each channel to affect processing on the other, you would need to process frames. An example of this might be a stereo ping-pong delay plugin where left and right channel data are both needed on a sample-by-sample basis. Another example is a stereo-linked compressor, whose side-chain information is derived from both left and right inputs in a way such that the left channel cannot be processed without the right channel, and vice-versa. For all of our example plugin projects, we will use frame-based processing. The reasons are:<br />
 <br />
 • Frame processing is simpler to understand – you do not need to keep track of buffer sample counters or pointers<br />
 • Frame processing is universal – all plugin algorithms may be viewed as frame processing systems, even if the channels do not interact; the opposite is not true for buffer processing<br />
 • Frame processing follows more closely how our algorithms are encoded, both in DSP difference equations as well as flowcharts and signal flow diagrams<br />
 <br />
 If you want to process buffers instead of frames, the method is simple: override the <em>processAudioBuffers</em> function and implement it. If you look in your plugincore.h file, you will see that the buffer processing function is commented out. To use it, un-comment it and implement the function in the plugincore.cpp file. <br />
 <br />
 // &mdash; uncomment and override this for buffer processing<br />
 <b>virtual bool processAudioBuffers(ProcessBufferInfo&amp; processBufferInfo);</b><br />
 <br />
 You can use the <em>processAudioBuffers</em> implementation in the pluginbase.cpp file to help you understand the arguments in the <a class="el" href="struct_process_buffer_info.html" title="Information package that arrives with each new audio buffer process cycle. Contains everything needed...">ProcessBufferInfo</a> structure (it is actually very straightforward). One cautionary comment is needed here: many users will try to process buffers because they are using an algorithm like the FFT that is designed to process blocks of data rather than frames of data and that is perfectly OK. The problem lies in the buffer sizes. In some DAWs, the user sets the buffer size in an audio buffer setup panel. In others, the buffer size is set in the DAW. In others, the buffer size is never guaranteed to be the same from one buffer process call to the next. For example, the AU API specifies that automation will be handled by breaking buffers into smaller pieces, each of which is processed with one set of parameter values. <b>You should never assume that the size of the incoming audio buffers will be fixed and unchanging and you should not try to tie your buffer-based processing to the audio buffer sizes.</b> There are just too many unknowns across the different APIs and the different DAW manufacturers that interpret those APIs. If your algorithm processes blocks of data, then you will be responsible for filling your own local buffers with data. You should expect that you might receive larger or smaller buffers than your processing calls for. You should also expect to receive partially filled or incomplete buffers from time to time, based on system overhead or the end-of-audio-file situation. <br />
 <br />
 Another issue with buffer based processing involves parameter smoothing. In order to make GUI control changes less glitch-y, we can smooth and update their parameters on each sample interval. If you are processing buffers, then this operation is going to break your buffer processing into sample interval chunks. So, if you want to use parameter smoothing, you might consider always processing frames rather than buffers.<br />
 <br />
 </p>
</div></div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a class="el" href="index.html">ASPiK Developer&#39;s Guide</a></li><li class="navelem"><a class="el" href="simple_plugin.html">Write a Plugin</a></li>
    <li class="footer">Generated by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.8.14 </li>
  </ul>
</div>
</body>
</html>
